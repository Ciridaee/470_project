{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3410f9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Accuracy: 0.5323\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from textstat import flesch_reading_ease, automated_readability_index\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# SpaCy yÃ¼klemesi\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    nlp = None\n",
    "\n",
    "# Model ve preprocessing bileÅŸenleri yÃ¼kleniyor\n",
    "try:\n",
    "    lstm_model = tf.keras.models.load_model(\".ipynb_checkpoints/lstm_model.h5\")\n",
    "    with open('.ipynb_checkpoints/preprocessing_components.pkl', 'rb') as f:\n",
    "        preprocessing = pickle.load(f)\n",
    "    sequence_length = preprocessing['sequence_length']\n",
    "    num_text_features = preprocessing['num_text_features'] \n",
    "    num_fin_features = preprocessing['num_fin_features']\n",
    "    financial_keywords = preprocessing['financial_keywords']\n",
    "except Exception as e:\n",
    "    print(\"Model veya preprocessing dosyasÄ± yÃ¼klenemedi:\", e)\n",
    "    exit()\n",
    "\n",
    "# Veri yÃ¼kleme\n",
    "test_data = pd.read_csv('stockMarket_predict/archive/reliance/finaldata_updated_labels.csv')\n",
    "\n",
    "# Metin temizleme\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"b['\\\"]|['\\\"]\", \"\", text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\d+', 'NUMBER', text)\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Sequence oluÅŸturma\n",
    "def create_sequence(dataframe, sequence_length):\n",
    "    x_seq, y_seq = [], []\n",
    "    for i in range(len(dataframe) - sequence_length):\n",
    "        seq = dataframe.iloc[i:i + sequence_length]\n",
    "        x_seq.append(seq.drop(columns=[\"Date\", \"label\"]).values)\n",
    "        y_seq.append(dataframe.iloc[i + sequence_length][\"label\"])\n",
    "    return x_seq, y_seq\n",
    "\n",
    "# Tarih ve temizleme iÅŸlemleri\n",
    "test_data[\"Date\"] = pd.to_datetime(test_data[\"Date\"], format=\"%d-%m-%Y\")\n",
    "test_data = test_data.sort_values(\"Date\").reset_index(drop=True)\n",
    "test_data['Combined'] = test_data.iloc[:, 2:27].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "test_data['Cleaned'] = test_data['Combined'].apply(clean_text)\n",
    "\n",
    "# Sentiment skorlarÄ±\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment_df = test_data['Cleaned'].apply(lambda x: pd.Series(sia.polarity_scores(x)))\n",
    "\n",
    "test_data['Compound'] = sentiment_df['compound']\n",
    "test_data['Positive'] = sentiment_df['pos']\n",
    "test_data['Negative'] = sentiment_df['neg']\n",
    "test_data['Neutral'] = sentiment_df['neu']\n",
    "test_data['headlines'] = 1\n",
    "\n",
    "# GÃ¼nlÃ¼k Ã¶zellikler\n",
    "daily_data = test_data.groupby(\"Date\").agg(\n",
    "    Compound_mean=('Compound', 'mean'),\n",
    "    Compound_max=('Compound', 'max'),\n",
    "    Compound_std=('Compound', 'std'),\n",
    "    Positive_mean=('Positive', 'mean'),\n",
    "    Positive_max=('Positive', 'max'),\n",
    "    Negative_mean=('Negative', 'mean'),\n",
    "    Negative_max=('Negative', 'max'),\n",
    "    Neutral_mean=('Neutral', 'mean'),\n",
    "    Neutral_max=('Neutral', 'max'),\n",
    "    headline_count=('headlines', 'count'),\n",
    "    label=('label', 'first')\n",
    ").fillna(0)\n",
    "\n",
    "# Ek zaman serisi Ã¶zellikleri\n",
    "daily_data = daily_data.reset_index().sort_values('Date')\n",
    "daily_data[\"volume_trend\"] = daily_data[\"headline_count\"].diff(periods=3)\n",
    "daily_data[\"compound_momentum\"] = daily_data[\"Compound_mean\"].diff().ewm(alpha=0.3).mean()\n",
    "daily_data[\"pos_trend\"] = daily_data[\"Positive_mean\"].diff(periods=3)\n",
    "daily_data[\"neg_trend\"] = daily_data[\"Negative_mean\"].diff(periods=3)\n",
    "daily_data = daily_data.fillna(0)\n",
    "\n",
    "# Sequence oluÅŸtur\n",
    "X_seq, y_seq = create_sequence(daily_data, sequence_length)\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# Test bÃ¶lme\n",
    "split_index = int(0.8 * len(X_seq))\n",
    "X_test = X_seq[split_index:]\n",
    "y_test = y_seq[split_index:]\n",
    "\n",
    "# Feature'larÄ± ayÄ±r\n",
    "text_features = X_test[:, :, :num_text_features]\n",
    "fin_features = X_test[:, :, num_text_features:]\n",
    "\n",
    "# ğŸ”§ MODELÄ°N BEKLEDÄ°ÄÄ° BOYUTA GETÄ°RME (Padding)\n",
    "\n",
    "# Modelin beklediÄŸi feature sayÄ±larÄ±\n",
    "expected_text_features = 15\n",
    "expected_fin_features = 2\n",
    "\n",
    "# Text input padding\n",
    "if text_features.shape[2] < expected_text_features:\n",
    "    pad_width = expected_text_features - text_features.shape[2]\n",
    "    text_padding = np.zeros((text_features.shape[0], text_features.shape[1], pad_width))\n",
    "    text_features = np.concatenate([text_features, text_padding], axis=2)\n",
    "\n",
    "# Financial input padding\n",
    "if fin_features.shape[2] < expected_fin_features:\n",
    "    pad_width = expected_fin_features - fin_features.shape[2]\n",
    "    fin_padding = np.zeros((fin_features.shape[0], fin_features.shape[1], pad_width))\n",
    "    fin_features = np.concatenate([fin_features, fin_padding], axis=2)\n",
    "\n",
    "# Tahmin ve deÄŸerlendirme\n",
    "y_pred_probs = lstm_model.predict([text_features, fin_features])\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
