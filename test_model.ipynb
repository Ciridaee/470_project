{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14171a1",
   "metadata": {},
   "source": [
    "# Model Test Notebook\n",
    "## Halil Melih AKÇA 221104091\n",
    "\n",
    "Bu notebook, eğitilmiş modelin `Combined_News_DJIA_table.csv` verileri ile performans testini yapar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12976800",
   "metadata": {},
   "source": [
    "## Gerekli Kütüphaneleri Import Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c11999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ VADER sentiment analyzer loaded\n",
      "✓ spaCy model loaded\n",
      "✓ textstat library loaded\n",
      "\n",
      "✅ Kütüphaneler yüklendi!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# NLP libraries\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    print(\"✓ VADER sentiment analyzer loaded\")\n",
    "except:\n",
    "    print(\"✗ VADER not available\")\n",
    "    sia = None\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✓ spaCy model loaded\")\n",
    "except:\n",
    "    print(\"✗ spaCy model not available\")\n",
    "    nlp = None\n",
    "\n",
    "try:\n",
    "    from textstat import flesch_reading_ease, automated_readability_index\n",
    "    print(\"✓ textstat library loaded\")\n",
    "except:\n",
    "    print(\"✗ textstat not available\")\n",
    "    flesch_reading_ease = lambda x: 0\n",
    "    automated_readability_index = lambda x: 0\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"\\n✅ Kütüphaneler yüklendi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0cdbf",
   "metadata": {},
   "source": [
    "## Veri Yükleme ve Model Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836f467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Hiçbir veri dosyası bulunamadı!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✗ Hiçbir veri dosyası bulunamadı!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m         exit()\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVeri kaynağı: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdata_source\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVeri boyutu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSütunlar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(test_df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_source' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test verilerini yükle\n",
    "try:\n",
    "    # İlk önce Combined_News_DJIA.csv'yi dene (orijinal)\n",
    "    test_df = pd.read_csv(\"../stockMarket_predict/Combined_News_DJIA.csv\")\n",
    "    print(f\"✓ Original dataset loaded: {test_df.shape}\")\n",
    "    data_source = \"Combined_News_DJIA.csv\"\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        # Sonra upload_DJIA_table.csv'yi dene\n",
    "        test_df = pd.read_csv(\"../stockMarket_predict/upload_DJIA_table.csv\")\n",
    "        print(f\"✓ Upload dataset loaded: {test_df.shape}\")\n",
    "        data_source = \"upload_DJIA_table.csv\"\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ Hiçbir veri dosyası bulunamadı!\")\n",
    "        exit()\n",
    "\n",
    "print(f\"\\nVeri kaynağı: {data_source}\")\n",
    "print(f\"Veri boyutu: {test_df.shape}\")\n",
    "print(f\"Sütunlar: {list(test_df.columns)}\")\n",
    "\n",
    "# Eğitilmiş modeli yükle\n",
    "try:\n",
    "    with open(\"ensemble_model.pkl\", \"rb\") as f:\n",
    "        trained_model = pickle.load(f)\n",
    "    print(\"\\n✓ Eğitilmiş ensemble model yüklendi\")\n",
    "    print(f\"Model tipi: {type(trained_model).__name__}\")\n",
    "    if hasattr(trained_model, 'estimators'):\n",
    "        print(f\"Base estimators: {len(trained_model.estimators)}\")\n",
    "        for name, estimator in trained_model.estimators:\n",
    "            print(f\"  - {name}: {type(estimator).__name__}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n✗ Model dosyası bulunamadı! Önce training notebook'u çalıştırın.\")\n",
    "    trained_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924db045",
   "metadata": {},
   "source": [
    "## Feature Engineering Fonksiyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ef3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orijinal notebook'taki feature engineering fonksiyonları\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Metin temizleme fonksiyonu\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"b['\\\"]|['\\\"]\", \"\", text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\d+', 'NUMBER', text)\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def linguistic_features(text):\n",
    "    \"\"\"Linguistik özellikler çıkarma\"\"\"\n",
    "    words = text.split()\n",
    "    avg_word_len = np.mean([len(w) for w in words]) if words else 0\n",
    "    punct_count = sum([1 for c in text if c in string.punctuation])\n",
    "    cap_ratio = sum([1 for c in text if c.isupper()]) / (len(text) + 1e-9)\n",
    "    digit_ratio = sum([1 for c in text if c.isdigit()]) / (len(text) + 1e-9)\n",
    "    \n",
    "    try:\n",
    "        flesch = flesch_reading_ease(text)\n",
    "        ari = automated_readability_index(text)\n",
    "    except:\n",
    "        flesch = 0\n",
    "        ari = 0\n",
    "    \n",
    "    return [len(words), avg_word_len, punct_count, cap_ratio, digit_ratio, flesch, ari]\n",
    "\n",
    "def pos_features_spacy(text):\n",
    "    \"\"\"POS tag özellikleri (spaCy ile)\"\"\"\n",
    "    if nlp is None:\n",
    "        return [0.25, 0.25, 0.25, 0.25]  # Default değerler\n",
    "    \n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        total = len(doc)\n",
    "        if total == 0:\n",
    "            return [0, 0, 0, 0]\n",
    "        noun_ratio = len([token for token in doc if token.pos_ == \"NOUN\"]) / total\n",
    "        verb_ratio = len([token for token in doc if token.pos_ == \"VERB\"]) / total\n",
    "        adj_ratio = len([token for token in doc if token.pos_ == \"ADJ\"]) / total\n",
    "        adv_ratio = len([token for token in doc if token.pos_ == \"ADV\"]) / total\n",
    "        return [noun_ratio, verb_ratio, adj_ratio, adv_ratio]\n",
    "    except:\n",
    "        return [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "financial_keywords = [\"bull\", \"bear\", \"gain\", \"loss\", \"stock\", \"market\"]\n",
    "\n",
    "def financial_keyword_density(text):\n",
    "    \"\"\"Finansal anahtar kelime yoğunluğu\"\"\"\n",
    "    tokens = text.lower().split()\n",
    "    return [tokens.count(word)/len(tokens) if len(tokens) > 0 else 0 for word in financial_keywords]\n",
    "\n",
    "def ner_features(text):\n",
    "    \"\"\"Named Entity Recognition özellikleri\"\"\"\n",
    "    if nlp is None:\n",
    "        return [0, 0, 0, 0]  # Default değerler\n",
    "    \n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        counts = {\"PERSON\":0, \"ORG\":0, \"GPE\":0, \"MONEY\":0}\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in counts:\n",
    "                counts[ent.label_] += 1\n",
    "        return list(counts.values())\n",
    "    except:\n",
    "        return [0, 0, 0, 0]\n",
    "\n",
    "print(\"✅ Feature engineering fonksiyonları tanımlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17375bf8",
   "metadata": {},
   "source": [
    "## Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01546f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi hazırla\n",
    "print(\"=== VERİ ÖN İŞLEME ===\")\n",
    "\n",
    "# Haberleri birleştir (2-27 arası sütunlar)\n",
    "if test_df.shape[1] >= 27:\n",
    "    test_df['Combined'] = test_df.iloc[:, 2:27].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "else:\n",
    "    # Eğer sütun sayısı az ise, mevcut tüm haber sütunlarını kullan\n",
    "    news_columns = [col for col in test_df.columns if col not in ['Date', 'Label']]\n",
    "    test_df['Combined'] = test_df[news_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# Metinleri temizle\n",
    "test_df['Cleaned'] = test_df['Combined'].apply(clean_text)\n",
    "\n",
    "print(f\"✓ {len(test_df)} örnek işlendi\")\n",
    "print(f\"✓ Ortalama metin uzunluğu: {test_df['Cleaned'].str.len().mean():.1f} karakter\")\n",
    "\n",
    "# Label kontrolü\n",
    "if 'Label' in test_df.columns:\n",
    "    print(f\"\\n📊 Label Dağılımı:\")\n",
    "    label_counts = test_df['Label'].value_counts()\n",
    "    for label, count in label_counts.items():\n",
    "        percentage = (count / len(test_df)) * 100\n",
    "        print(f\"  Label {label}: {count} örnek ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"⚠️ Label sütunu bulunamadı - sadece tahmin yapılacak\")\n",
    "\n",
    "# İlk birkaç örneği göster\n",
    "print(\"\\n📝 İlk 3 örnek:\")\n",
    "for i in range(min(3, len(test_df))):\n",
    "    text = test_df['Cleaned'].iloc[i][:100] + \"...\" if len(test_df['Cleaned'].iloc[i]) > 100 else test_df['Cleaned'].iloc[i]\n",
    "    label = test_df['Label'].iloc[i] if 'Label' in test_df.columns else \"?\"\n",
    "    print(f\"  {i+1}. Label: {label} | Text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83abaa3",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73075c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FEATURE EXTRACTION ===\")\n",
    "\n",
    "# 1. Linguistik özellikler\n",
    "print(\"📊 Linguistik özellikler çıkarılıyor...\")\n",
    "ling_features = test_df['Cleaned'].apply(linguistic_features)\n",
    "ling_df = pd.DataFrame(ling_features.tolist(), \n",
    "                      columns=[\"word_count\", \"avg_word_len\", \"punct_count\", \n",
    "                              \"cap_ratio\", \"digit_ratio\", \"flesch\", \"ari\"])\n",
    "print(f\"  ✓ {ling_df.shape[1]} linguistik özellik çıkarıldı\")\n",
    "\n",
    "# 2. Sentiment özellikleri\n",
    "print(\"😊 Sentiment özellikleri çıkarılıyor...\")\n",
    "if sia is not None:\n",
    "    sentiment_features = test_df['Cleaned'].apply(lambda x: pd.Series(sia.polarity_scores(x)))\n",
    "    print(f\"  ✓ {sentiment_features.shape[1]} sentiment özellik çıkarıldı\")\n",
    "else:\n",
    "    sentiment_features = pd.DataFrame({\n",
    "        'neg': [0] * len(test_df), 'neu': [0.5] * len(test_df), \n",
    "        'pos': [0] * len(test_df), 'compound': [0] * len(test_df)\n",
    "    })\n",
    "    print(\"  ⚠️ VADER kullanılamadı, default değerler kullanıldı\")\n",
    "\n",
    "# 3. POS özellikleri\n",
    "print(\"🏷️ POS tag özellikleri çıkarılıyor...\")\n",
    "pos_features = test_df['Cleaned'].apply(pos_features_spacy)\n",
    "pos_df = pd.DataFrame(pos_features.tolist(), \n",
    "                     columns=[\"noun_ratio\", \"verb_ratio\", \"adj_ratio\", \"adv_ratio\"])\n",
    "print(f\"  ✓ {pos_df.shape[1]} POS özellik çıkarıldı\")\n",
    "\n",
    "# 4. Finansal anahtar kelime özellikleri\n",
    "print(\"💰 Finansal anahtar kelime özellikleri çıkarılıyor...\")\n",
    "fin_features = test_df['Cleaned'].apply(financial_keyword_density)\n",
    "fin_df = pd.DataFrame(fin_features.tolist(), \n",
    "                     columns=[f'kw_{k}' for k in financial_keywords])\n",
    "print(f\"  ✓ {fin_df.shape[1]} finansal özellik çıkarıldı\")\n",
    "\n",
    "# 5. NER özellikleri\n",
    "print(\"🏢 Named Entity özellikleri çıkarılıyor...\")\n",
    "ner_features = test_df['Cleaned'].apply(ner_features)\n",
    "ner_df = pd.DataFrame(ner_features.tolist(), \n",
    "                     columns=[\"PERSON\", \"ORG\", \"GPE\", \"MONEY\"])\n",
    "print(f\"  ✓ {ner_df.shape[1]} NER özellik çıkarıldı\")\n",
    "\n",
    "# 6. TF-IDF özellikleri (PCA ile boyut azaltma)\n",
    "print(\"📝 TF-IDF özellikleri çıkarılıyor...\")\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), \n",
    "                       min_df=2, max_df=0.95, stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(test_df['Cleaned'])\n",
    "pca = PCA(n_components=50)\n",
    "tfidf_pca = pca.fit_transform(tfidf_matrix.toarray())\n",
    "tfidf_df = pd.DataFrame(tfidf_pca, columns=[f'pca_{i}' for i in range(tfidf_pca.shape[1])])\n",
    "print(f\"  ✓ {tfidf_df.shape[1]} TF-IDF+PCA özellik çıkarıldı\")\n",
    "\n",
    "# Tüm özellikleri birleştir\n",
    "all_features = pd.concat([ling_df, sentiment_features, pos_df, fin_df, ner_df, tfidf_df], axis=1)\n",
    "\n",
    "print(f\"\\n✅ Toplam {all_features.shape[1]} özellik çıkarıldı!\")\n",
    "print(f\"📊 Feature matrix boyutu: {all_features.shape}\")\n",
    "\n",
    "# Feature istatistikleri\n",
    "print(\"\\n📈 Feature İstatistikleri:\")\n",
    "print(f\"  - Linguistik: {ling_df.shape[1]} özellik\")\n",
    "print(f\"  - Sentiment: {sentiment_features.shape[1]} özellik\")\n",
    "print(f\"  - POS Tags: {pos_df.shape[1]} özellik\")\n",
    "print(f\"  - Finansal: {fin_df.shape[1]} özellik\")\n",
    "print(f\"  - NER: {ner_df.shape[1]} özellik\")\n",
    "print(f\"  - TF-IDF+PCA: {tfidf_df.shape[1]} özellik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95e48f",
   "metadata": {},
   "source": [
    "## Feature Scaling ve Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FEATURE SCALING VE TRANSFORMATION ===\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(all_features.values)\n",
    "print(f\"✓ Feature scaling tamamlandı\")\n",
    "\n",
    "# Polynomial features (eğitim sırasında kullanıldıysa)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "print(f\"✓ Polynomial features oluşturuldu\")\n",
    "print(f\"📊 Final feature matrix boyutu: {X_poly.shape}\")\n",
    "\n",
    "# Memory kullanımı kontrolü\n",
    "memory_usage_mb = X_poly.nbytes / (1024 * 1024)\n",
    "print(f\"💾 Memory kullanımı: {memory_usage_mb:.1f} MB\")\n",
    "\n",
    "if memory_usage_mb > 1000:\n",
    "    print(\"⚠️ Yüksek memory kullanımı tespit edildi!\")\n",
    "else:\n",
    "    print(\"✅ Memory kullanımı kabul edilebilir seviyede\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e766e73",
   "metadata": {},
   "source": [
    "## Model Test ve Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MODEL TEST VE TAHMİN ===\")\n",
    "\n",
    "if trained_model is None:\n",
    "    print(\"❌ Model yüklenmediği için tahmin yapılamıyor!\")\n",
    "else:\n",
    "    try:\n",
    "        # Model ile tahmin yap\n",
    "        print(\"🤖 Model ile tahminler yapılıyor...\")\n",
    "        y_pred = trained_model.predict(X_poly)\n",
    "        \n",
    "        # Prediction probabilities (eğer mevcut ise)\n",
    "        try:\n",
    "            y_pred_proba = trained_model.predict_proba(X_poly)\n",
    "            print(\"✓ Tahmin olasılıkları da hesaplandı\")\n",
    "        except:\n",
    "            y_pred_proba = None\n",
    "            print(\"⚠️ Model predict_proba desteklemiyor\")\n",
    "        \n",
    "        print(f\"✅ {len(y_pred)} tahmin başarıyla yapıldı!\")\n",
    "        \n",
    "        # Tahmin dağılımı\n",
    "        print(\"\\n📊 Tahmin Dağılımı:\")\n",
    "        pred_counts = pd.Series(y_pred).value_counts().sort_index()\n",
    "        for pred, count in pred_counts.items():\n",
    "            percentage = (count / len(y_pred)) * 100\n",
    "            print(f\"  Prediction {pred}: {count} örnek ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Eğer gerçek labellar varsa, performans metriklerini hesapla\n",
    "        if 'Label' in test_df.columns:\n",
    "            y_true = test_df['Label'].values\n",
    "            \n",
    "            print(\"\\n🎯 PERFORMANS METRİKLERİ:\")\n",
    "            \n",
    "            # Accuracy\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            print(f\"📈 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "            \n",
    "            # F1 Score\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "            print(f\"📈 F1 Score: {f1:.4f}\")\n",
    "            \n",
    "            # Classification Report\n",
    "            print(\"\\n📋 Detaylı Classification Report:\")\n",
    "            print(classification_report(y_true, y_pred))\n",
    "            \n",
    "            # Confusion Matrix\n",
    "            print(\"\\n🧩 Confusion Matrix:\")\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            print(cm)\n",
    "            \n",
    "            # Confusion Matrix Visualization\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                       xticklabels=['Down (0)', 'Up (1)'], \n",
    "                       yticklabels=['Down (0)', 'Up (1)'])\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.ylabel('Gerçek Label')\n",
    "            plt.xlabel('Tahmin Edilen Label')\n",
    "            plt.show()\n",
    "            \n",
    "            # Baseline ile karşılaştırma\n",
    "            baseline_accuracy = max(pd.Series(y_true).value_counts(normalize=True))\n",
    "            print(f\"\\n📊 Baseline Accuracy (Majority Class): {baseline_accuracy:.4f}\")\n",
    "            improvement = accuracy - baseline_accuracy\n",
    "            print(f\"📈 Model İyileştirmesi: {improvement:.4f} ({improvement*100:.2f} percentage points)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n⚠️ Gerçek labellar olmadığı için performans metrikleri hesaplanamıyor\")\n",
    "            print(\"Sadece tahminler yapıldı.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Tahmin sırasında hata oluştu: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9de6da",
   "metadata": {},
   "source": [
    "## Tahmin Örnekleri ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c23dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained_model is not None and 'y_pred' in locals():\n",
    "    print(\"=== TAHMİN ÖRNEKLERİ VE ANALİZ ===\")\n",
    "    \n",
    "    # Tahmin sonuçlarını dataframe'e ekle\n",
    "    results_df = test_df.copy()\n",
    "    results_df['Prediction'] = y_pred\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        results_df['Prob_Down'] = y_pred_proba[:, 0]\n",
    "        results_df['Prob_Up'] = y_pred_proba[:, 1]\n",
    "        results_df['Confidence'] = np.max(y_pred_proba, axis=1)\n",
    "    \n",
    "    # İlk 10 örneği göster\n",
    "    print(\"\\n📝 İlk 10 Tahmin Örneği:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i in range(min(10, len(results_df))):\n",
    "        text = results_df['Cleaned'].iloc[i][:80] + \"...\" if len(results_df['Cleaned'].iloc[i]) > 80 else results_df['Cleaned'].iloc[i]\n",
    "        pred = results_df['Prediction'].iloc[i]\n",
    "        pred_text = \"📈 UP\" if pred == 1 else \"📉 DOWN\"\n",
    "        \n",
    "        if 'Label' in results_df.columns:\n",
    "            true_label = results_df['Label'].iloc[i]\n",
    "            true_text = \"📈 UP\" if true_label == 1 else \"📉 DOWN\"\n",
    "            correct = \"✅\" if pred == true_label else \"❌\"\n",
    "            \n",
    "            if 'Confidence' in results_df.columns:\n",
    "                confidence = results_df['Confidence'].iloc[i]\n",
    "                print(f\"{i+1:2d}. {correct} Gerçek: {true_text} | Tahmin: {pred_text} | Güven: {confidence:.3f}\")\n",
    "            else:\n",
    "                print(f\"{i+1:2d}. {correct} Gerçek: {true_text} | Tahmin: {pred_text}\")\n",
    "        else:\n",
    "            if 'Confidence' in results_df.columns:\n",
    "                confidence = results_df['Confidence'].iloc[i]\n",
    "                print(f\"{i+1:2d}. Tahmin: {pred_text} | Güven: {confidence:.3f}\")\n",
    "            else:\n",
    "                print(f\"{i+1:2d}. Tahmin: {pred_text}\")\n",
    "        \n",
    "        print(f\"    Text: {text}\")\n",
    "        print()\n",
    "    \n",
    "    # Güven düzeyi analizi (eğer varsa)\n",
    "    if 'Confidence' in results_df.columns:\n",
    "        print(\"\\n📊 Güven Düzeyi Analizi:\")\n",
    "        print(f\"  Ortalama güven: {results_df['Confidence'].mean():.3f}\")\n",
    "        print(f\"  Minimum güven: {results_df['Confidence'].min():.3f}\")\n",
    "        print(f\"  Maksimum güven: {results_df['Confidence'].max():.3f}\")\n",
    "        \n",
    "        # Güven düzeyi histogramı\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(results_df['Confidence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.title('Model Güven Düzeyi Dağılımı')\n",
    "        plt.xlabel('Güven Düzeyi')\n",
    "        plt.ylabel('Frekans')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        # Yüksek ve düşük güvenli tahminler\n",
    "        high_conf = results_df[results_df['Confidence'] > 0.8]\n",
    "        low_conf = results_df[results_df['Confidence'] < 0.6]\n",
    "        \n",
    "        print(f\"\\n🎯 Yüksek güvenli tahminler (>0.8): {len(high_conf)} örnek\")\n",
    "        print(f\"🤔 Düşük güvenli tahminler (<0.6): {len(low_conf)} örnek\")\n",
    "        \n",
    "        if 'Label' in results_df.columns and len(high_conf) > 0:\n",
    "            high_conf_accuracy = accuracy_score(high_conf['Label'], high_conf['Prediction'])\n",
    "            print(f\"📈 Yüksek güvenli tahminlerde accuracy: {high_conf_accuracy:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Model tahminleri mevcut değil, analiz yapılamıyor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48565510",
   "metadata": {},
   "source": [
    "## Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffa492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"                    MODEL TEST RAPORU\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n📊 TEST VERİSİ BİLGİLERİ:\")\n",
    "print(f\"  📁 Veri kaynağı: {data_source}\")\n",
    "print(f\"  📈 Toplam örnek sayısı: {len(test_df)}\")\n",
    "print(f\"  🔧 Çıkarılan feature sayısı: {all_features.shape[1]}\")\n",
    "print(f\"  ⚙️ Final feature matrix: {X_poly.shape}\")\n",
    "\n",
    "if 'Label' in test_df.columns:\n",
    "    print(f\"\\n🎯 LABEL BİLGİLERİ:\")\n",
    "    label_counts = test_df['Label'].value_counts().sort_index()\n",
    "    for label, count in label_counts.items():\n",
    "        percentage = (count / len(test_df)) * 100\n",
    "        direction = \"📉 DOWN\" if label == 0 else \"📈 UP\"\n",
    "        print(f\"  {direction}: {count} örnek ({percentage:.1f}%)\")\n",
    "\n",
    "if trained_model is not None:\n",
    "    print(f\"\\n🤖 MODEL BİLGİLERİ:\")\n",
    "    print(f\"  🔧 Model tipi: {type(trained_model).__name__}\")\n",
    "    if hasattr(trained_model, 'estimators'):\n",
    "        print(f\"  👥 Base estimator sayısı: {len(trained_model.estimators)}\")\n",
    "        for name, estimator in trained_model.estimators:\n",
    "            print(f\"     - {name}: {type(estimator).__name__}\")\n",
    "    \n",
    "    if 'y_pred' in locals() and 'Label' in test_df.columns:\n",
    "        print(f\"\\n📈 PERFORMANS METRİKLERİ:\")\n",
    "        print(f\"  🎯 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        print(f\"  🎯 F1 Score: {f1:.4f}\")\n",
    "        print(f\"  📊 Baseline Accuracy: {baseline_accuracy:.4f}\")\n",
    "        print(f\"  📈 Model İyileştirmesi: +{improvement:.4f} ({improvement*100:.2f} pp)\")\n",
    "        \n",
    "        # Performans değerlendirmesi\n",
    "        if accuracy > 0.55:\n",
    "            print(f\"  ✅ İyi performans! (>55%)\")\n",
    "        elif accuracy > 0.50:\n",
    "            print(f\"  ⚠️ Orta performans (50-55%)\")\n",
    "        else:\n",
    "            print(f\"  ❌ Düşük performans (<50%)\")\n",
    "            \n",
    "        if improvement > 0.05:\n",
    "            print(f\"  ✅ Baseline'dan anlamlı iyileştirme!\")\n",
    "        else:\n",
    "            print(f\"  ⚠️ Baseline'dan sınırlı iyileştirme\")\n",
    "else:\n",
    "    print(f\"\\n❌ Model yüklenemedi - performans testi yapılamadı\")\n",
    "\n",
    "print(f\"\\n💡 FİNANSAL SENTIMENT ANALİZ NOTLARI:\")\n",
    "print(f\"  • Haber sentiment analizi tipik olarak %45-60 accuracy gösterir\")\n",
    "print(f\"  • Haber verileri piyasa hareketlerinin sadece ~%3'ünü açıklar\")\n",
    "print(f\"  • %53 civarı accuracy finansal ML'de normal kabul edilir\")\n",
    "print(f\"  • Yüksek accuracy overfitting işareti olabilir\")\n",
    "\n",
    "print(f\"\\n⏰ Test tarihi: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"👤 Test eden: Halil Melih AKÇA (221104091)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✅ MODEL TEST TAMAMLANDI!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
